# Selective Amnesia on a Conditional VAE for MNIST

This repository contains Google Colab notebooks implementing a **selective unlearning** algorithm on a Conditional VAE (CVAE) for the MNIST dataset. The goal is to selectively "unlearn" or "forget" specific digit classes from a pre-trained CVAE model.

The project is inspired by concepts from the paper:
**Selective Amnesia: A Continual Learning Approach to Forgetting in Deep Generative Models**
(Alvin Heng, Harold Soh - arXiv:2305.10120)

---

## Tasks Completed

The notebook is structured to perform four main tasks:

### Implement Selective Unlearning (EWC-based)
A baseline CVAE is first trained on all 10 MNIST classes. Then, a selective unlearning algorithm is applied to "forget" a specified class. This is achieved by:

1.  **Calculating Fisher Information (FIM):** The FIM is calculated using only the **retain** classes. This identifies the model parameters most important for the classes we want to *keep*.
2.  **Fine-tuning:** The baseline model is fine-tuned with a 3-part loss function:
    * **$\mathcal{L}_{retain}$:** A reconstruction loss using real and replayed data from the *retain* classes.
    * **$\mathcal{L}_{EWC}$:** An **Elastic Weight Consolidation** penalty (using the FIM) that *protects* the important "retain" parameters from being changed.
    * **$\mathcal{L}_{neg}$:** A "gray-out" loss that forces the decoder to output a uniform gray image when conditioned on the *forget* class.

### Advanced Sequential Unlearning
To test the limits of the EWC "shield," we perform **sequential unlearning**:
1.  First, we unlearn **Class 9** from the baseline model.
2.  Then, we load the "forgot-9" model, calculate a *new* Fisher matrix (protecting classes 0-8), and unlearn **Class 2**.

### Visualize and Analyze the Latent Space
We analyze the effects of unlearning on the model's internal representations:
1.  **Latent Space (t-SNE) Plot:** We compare the t-SNE plot of the baseline model (showing 10 distinct clusters) to the unlearned models. 
2.  **Comparison Grid:** We test the **Decoder** by generating images for all 10 classes to visually confirm that the forgotten classes have turned gray.
3. 

### Attack the Unlearned Model
We attempt to generate the forgotten classes from the final, unlearned model. This is done by freezing the model and optimizing its inputs (`z` and `y`).
1.  **Reconstruction Attack (Prototype Matching):** We optimize `z` and `y` to force the unlearned decoder to reconstruct a "perfect" digit prototype (generated by the original *baseline* model).
2.  **Classifier-Guided Attack:** We use a separate MNIST classifier as a "judge" and optimize `z` and `y` to produce an image that *fools the judge* into believing it's the forgotten class.
